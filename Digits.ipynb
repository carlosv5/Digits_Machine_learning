{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](files/images/EscUpmPolit_p.gif \"UPM\")\n",
    "\n",
    "# Course Notes for Learning Intelligent Systems\n",
    "\n",
    "Department of Telematic Engineering Systems, Universidad Politécnica de Madrid, © 2016 Carlos A. Iglesias\n",
    "\n",
    "\n",
    "Student: Carlos Vega García"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ordert to read the dataset, we import the datasets bundle and then load the Digits dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import load_digits dataset from scikit-learn\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# load iris dataset\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have read the dataset we can see it characteristics and values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   5. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,  10.   0.   0.]\n",
      " [  0.   0.   0. ...,  16.   9.   0.]\n",
      " ..., \n",
      " [  0.   0.   1. ...,   6.   0.   0.]\n",
      " [  0.   0.   2. ...,  12.   0.   0.]\n",
      " [  0.   0.  10. ...,  12.   1.   0.]]\n",
      "(1797, 64)\n",
      "[0 1 2 ..., 8 9 8]\n",
      "(1797,)\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)\n",
    "print(digits.data.shape)\n",
    "print(digits.target)\n",
    "print(digits.target.shape)\n",
    "print(digits.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 1797 rows and 64 columns. So we have 1797 samples and 64 features. \n",
    "\n",
    "\n",
    "This features tell us the attributes of each sample and we have to find the correct number with them.\n",
    "\n",
    "\n",
    "We can see we have 1797 target values from 0 to 9. Each one represents the number that the person wrote.\n",
    "\n",
    "Each one of these 64 features represent the number of pixels (0 to 16) that a block(4x4) of the whole bitmap(32x32) has. So, we have an 8x8 matrix with these numbers of pixels.\n",
    "\n",
    "\n",
    "We also have the images of the numbers. They have 1797 rows, each one has 8x8 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset's webpage, they teach us how to visualize the images of the numbers. We can see all of them replacing the number of the row in the command plt.matshow(digits.images[Number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0ab41c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iI4gMJUXwgof8A4C6Y4wlBav8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0ab41c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kind of data (pixels of an image) make some types of plots useless. For example, I think it makes no sense the scatter diagrams because comparing pixels between images does not give us important information.\n",
    "\n",
    "#### Histogram\n",
    "\n",
    "We can see how many samples of each class we have using an histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0ab208588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram, the default is 10 bins\n",
    "%matplotlib inline\n",
    "plt.hist(digits.target)\n",
    "plt.ylabel('Number of instances')\n",
    "plt.xlabel('Digits class')\n",
    "plt.xticks(range(len(digits.target_names)), digits.target_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that each digit has more or less the same number of appearances in the data but not the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe\n",
    "\n",
    "We represent the data as a DataFrame object from the library pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2     3     4     5    6    7    8    9   ...     55   56   57  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0   ...    0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "\n",
       "    58    59    60    61   62   63  target  \n",
       "0  6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1  0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2  0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3  7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4  0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from pandas import DataFrame\n",
    "\n",
    "# transform into dataframe\n",
    "digits_df = DataFrame(digits.data)\n",
    "digits_df['target'] = digits.target\n",
    "digits_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see each row of Digits and the value of each pixel. We add the target column which shows the number this pixels represents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training set and Test set\n",
    "\n",
    "We separate the dataset in training data and test data. I'm going to take 25% of data to test. I take random_state 33 in order to have always the same distribution of data in the two types.\n",
    "\n",
    "\n",
    "(In the original data we have training and test data but we don't know what rows are of each type so I'm going to do this division in order to process the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_digits, y_digits = digits.data, digits.target\n",
    "# Test set will be the 25% taken randomly\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_digits, y_digits, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the number of rows we have for each purpose and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train and testing\n",
      "(1347, 64) (450, 64)\n",
      "Train set\n",
      "[[  0.   0.   1. ...,   0.   0.   0.]\n",
      " [  0.   0.   4. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,   0.   0.   0.]\n",
      " ..., \n",
      " [  0.   0.   4. ...,   0.   0.   0.]\n",
      " [  0.   0.  12. ...,   0.   0.   0.]\n",
      " [  0.   1.   7. ...,   0.   0.   0.]]\n",
      "Test set\n",
      "[[  0.   0.   4. ...,  11.   0.   0.]\n",
      " [  0.   0.   3. ...,  16.  10.   0.]\n",
      " [  0.   0.   7. ...,   0.   0.   0.]\n",
      " ..., \n",
      " [  0.   0.   6. ...,  12.   1.   0.]\n",
      " [  0.   0.   0. ...,  11.   1.   0.]\n",
      " [  0.   0.   0. ...,  16.  11.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of train and testing\n",
    "print(\"Dimensions of train and testing\") \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "#Train set\n",
    "print(\"Train set\") \n",
    "print (x_train)\n",
    "\n",
    "#Test set\n",
    "print(\"Test set\") \n",
    "print (x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "Now I'm going to Standardize the data in order to apply machine learning algorithms later. We need to have all the variables in the same units in order to have all of them the same weight in the algorithms. In this case I think it does not matter because the variables are all pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.32672314 -0.2423893  ...,  0.73926354 -0.49709493\n",
      "  -0.19054741]\n",
      " [ 0.         -0.32672314 -0.4534419  ...,  1.58229435  1.97553015\n",
      "  -0.19054741]\n",
      " [ 0.         -0.32672314  0.39076852 ..., -1.11540424 -0.49709493\n",
      "  -0.19054741]\n",
      " ..., \n",
      " [ 0.         -0.32672314  0.17971592 ...,  0.90786971 -0.24983242\n",
      "  -0.19054741]\n",
      " [ 0.         -0.32672314 -1.08659972 ...,  0.73926354 -0.24983242\n",
      "  -0.19054741]\n",
      " [ 0.         -0.32672314 -1.08659972 ...,  1.58229435  2.22279266\n",
      "  -0.19054741]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# The digits dataset is now  normalized\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning\n",
    "####  KNeighborsClassifier\n",
    "We have preprocessed the data. Now we are going to classify the rows depending on the K neighbours. In order to do that, firstly we have to create the model (we have to write the number of neighbours we are going to deal with). We are going to fit the model with the train rows, and finally we are going to predict the test results.\n",
    "\n",
    "I select 15 neighbours initially and we'll see the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create kNN model\n",
    "model = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction  [4 7 4 ..., 1 5 5]\n",
      "Expected  [4 7 4 ..., 1 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction \", model.predict(x_train))\n",
    "print(\"Expected \", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the precited results of the x_train rows and we can compare it with the expected results because they are the y_train. We can see it success in the 6 numbers it shows. So, now we are going to calculate the accuracy of the model, in other words, the probability of predicting right the number that the model has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training 0.973273942094\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Accuracy in training\n",
    "\n",
    "from sklearn import metrics\n",
    "y_train_pred = model.predict(x_train)\n",
    "print(\"Accuracy in training\", metrics.accuracy_score(y_train, y_train_pred))\n",
    "accuracy_knn_training1 = metrics.accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in testing  0.971111111111\n"
     ]
    }
   ],
   "source": [
    "# Now we evaluate error in testing\n",
    "y_test_pred = model.predict(x_test)\n",
    "print(\"Accuracy in testing \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "accuracy_knn_testing1 = metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is normal that the accuracy in test data is lower than in the training one because the adjust/fit of the model is done with training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we calculate the metrics of the model based on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          [       1.00      1.00      1.00        35\n",
      "          0       0.96      0.98      0.97        54\n",
      "                  1.00      1.00      1.00        44\n",
      "          1       0.98      0.96      0.97        46\n",
      "                  1.00      0.91      0.96        35\n",
      "          2       0.98      0.96      0.97        48\n",
      "                  0.98      1.00      0.99        51\n",
      "          .       0.97      1.00      0.99        35\n",
      "          .       0.90      0.95      0.92        58\n",
      "          .       0.98      0.95      0.97        44\n",
      "\n",
      "avg / total       0.97      0.97      0.97       450\n",
      "\n",
      "[1 3 7 3 2 4 6 1 4 0 4 7 8 9 2 8 3 6 7 0 6 0 8 3 0 6 2 3 0 9 0 2 0 6 9 1 1\n",
      " 5 8 0 6 1 5 8 9 5 1 6 2 6 6 7 6 7 7 2 7 8 0 7 3 6 3 9 6 6 5 5 4 2 9 3 7 6\n",
      " 5 7 2 8 1 2 2 8 1 1 6 3 5 0 0 1 6 7 5 8 9 7 0 0 9 8 0 8 2 3 6 1 9 9 1 7 8\n",
      " 9 8 8 5 9 5 1 1 9 9 3 3 2 8 1 3 8 6 4 0 0 0 7 1 5 5 1 8 5 1 8 8 6 9 9 4 5\n",
      " 7 5 2 1 2 3 8 7 7 5 1 9 1 9 8 0 6 1 2 1 3 3 8 9 6 8 4 1 0 0 9 8 7 2 8 6 4\n",
      " 8 9 4 2 6 1 8 5 6 7 5 1 9 2 8 3 2 9 4 8 5 5 6 2 4 3 2 6 4 8 5 8 0 8 8 6 3\n",
      " 2 3 0 5 7 1 3 9 3 2 1 6 6 5 1 9 7 2 4 5 2 1 3 1 1 2 1 7 0 1 2 2 1 2 4 9 6\n",
      " 6 3 9 2 8 1 5 5 1 8 6 2 5 6 0 1 4 2 1 8 9 4 3 0 6 8 3 3 2 0 2 5 6 5 6 6 4\n",
      " 6 1 8 3 4 1 3 5 1 4 9 8 7 5 1 1 3 7 8 8 3 7 4 0 7 2 9 7 1 9 4 5 3 5 2 5 1\n",
      " 3 0 5 8 4 7 6 9 9 3 3 4 8 6 4 7 0 6 8 2 3 3 4 5 3 3 5 2 0 9 7 1 5 5 8 4 4\n",
      " 3 6 2 5 1 0 6 1 5 8 4 9 6 4 3 8 0 3 0 1 2 8 0 5 4 5 2 8 9 6 9 8 0 8 8 2 4\n",
      " 6 5 6 4 3 9 8 9 7 1 7 9 4 1 5 9 5 9 8 6 8 2 5 1 4 2 6 3 7 9 8 7 4 3 7 1 8\n",
      " 8 9 5 3 6 6]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_test_pred, target_names=str(digits.target)))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision says the proportion of predicted instances as a target digit that are correctly predicted.\n",
    "\n",
    "\n",
    "The Recall counts the proportion of predicted digits that were correctly evaluated (correct digit prediction versus the total number of this target digit that exist in the dataset).\n",
    "\n",
    "\n",
    "The F1-Score is a proportion between these two metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the confusion matrix we can see how many times the model predicts a number wrong and which is the wrong number, in other words, the confusion between digits in the prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 53  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 44  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  0  2  0]\n",
      " [ 0  0  0  0 32  0  0  1  2  0]\n",
      " [ 0  0  0  0  0 46  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 51  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 35  0  0]\n",
      " [ 0  2  0  1  0  0  0  0 55  0]\n",
      " [ 0  0  0  0  0  1  0  0  1 42]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, with test data, the model always predicts right the digit 0. But with digit 1 it confuses it with the digit 8 one time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold validation\n",
    "We do K-fold validation with k = 10. So the model it is going to train with 9 distincts parts of the data each time and test with the one remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
    "model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# create a k-fold cross validation iterator of k=10 folds\n",
    "cv = KFold(10, shuffle=True, random_state=33)\n",
    "\n",
    "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the accuracy of each combination in the 10 fold validation and we are going to calculate the mean of all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "def mean_score(scores):\n",
    "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
    "print(mean_score(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_range = range(1, 21)\n",
    "accuracy = []\n",
    "for k in k_range:\n",
    "    m = KNeighborsClassifier(k)\n",
    "    m.fit(x_train, y_train)\n",
    "    y_test_pred = m.predict(x_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "plt.plot(k_range, accuracy)\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see that the best K in KNN is 1 neighbours, so I'm going to repeat the algorithm with this k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create kNN model\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(x_train, y_train)\n",
    "from sklearn import metrics\n",
    "y_train_pred = model.predict(x_train)\n",
    "print(\"Accuracy in training\", metrics.accuracy_score(y_train, y_train_pred))\n",
    "accuracy_knn_training2 = metrics.accuracy_score(y_train, y_train_pred)\n",
    "# Now we evaluate error in testing\n",
    "y_test_pred = model.predict(x_test)\n",
    "print(\"Accuracy in testing \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "accuracy_knn_testing2 = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(metrics.classification_report(y_test, y_test_pred, target_names=str(digits.target)))\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here we can see it's right that it is better using K=1 neighbour. We have 100% accuracy in training and 98% accuracy in testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Learning\n",
    "The scikit-learn uses an optimised version of the CART algorithm(Classification and Regression Trees).\n",
    "\n",
    "\n",
    "We have the data loaded and preprocessed yet and now we are going to train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "max_depth=3\n",
    "random_state=33\n",
    "\n",
    "# Create decision tree model\n",
    "model = tree.DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Prediction \", model.predict(x_train))\n",
    "print(\"Expected \", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the predicted and expected digits we can see that the model is wrong with two of the train data predictions that the list shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Predicted probabilities\", model.predict_proba(x_train[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the accuracy of training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate Accuracy in training\n",
    "\n",
    "from sklearn import metrics\n",
    "y_train_pred = model.predict(x_train)\n",
    "print(\"Accuracy in training\", metrics.accuracy_score(y_train, y_train_pred))\n",
    "accuracy_tree_training1 = metrics.accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Now we evaluate error in testing\n",
    "y_test_pred = model.predict(x_test)\n",
    "print(\"Accuracy in testing \", metrics.accuracy_score(y_test, y_test_pred))\n",
    "accuracy_tree_testing1 = metrics.accuracy_score(y_test, y_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model is more accurate in training than in testing. It was the same in the knn algorithm and the explanation is the same: it is normal because the model was fitted with the training data. However, the results in accuracy are considerably worse than with knn algorithm. An accuracy lower than 50% means that the model predicts wrongly the digit more than half of the times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to evaluate the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_test_pred,target_names=str(digits.target_names)))\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the metrics are awful because the algorithm is not optimized. In the confusion matrix we realize that it predicts wrong the digit a lot of times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
    "model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('DecisionTree', DecisionTreeClassifier(max_depth=max_depth, random_state=random_state))\n",
    "])\n",
    "\n",
    "# create a k-fold cross validation iterator of k=10 folds\n",
    "cv = KFold(10, shuffle=True, random_state=33)\n",
    "\n",
    "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
    "print(scores)\n",
    "def mean_score(scores):\n",
    "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
    "print(mean_score(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k-fold evaluation the results are more or less the same but still worse than knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Grid Search for Parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an optimization technique. We are going to use it in order to find the optimal value of some parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {'max_depth': np.arange(3, 10)} \n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(), param_grid)\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"Best score: \", gs.best_score_)\n",
    "print(\"Best params: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the optimal max depth (from 3 to 10) of the tree in the Decision Tree Learning algorithm is 9. We can see the accuracy using different depths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We print the score for each value of max_depth\n",
    "for i, max_depth in enumerate(gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (gs.cv_results_['mean_test_score'][i],\n",
    "                                        gs.cv_results_['std_test_score'][i] * 2,\n",
    "                                        max_depth))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the other parameters we can modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code repeats the grid search with every combination of the parameters set and give us the optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# set of parameters to test\n",
    "tuned_parameters = [{'max_depth': np.arange(3, 15),\n",
    "                     'criterion': ['gini', 'entropy'], \n",
    "                     'splitter': ['best', 'random'],\n",
    "                     'class_weight':['balanced', None],\n",
    "                     'max_leaf_nodes': [None,10,16,20],\n",
    "                     'random_state':[33]\n",
    "                    }]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    # cv = the fold of the cross-validation cv, defaulted to 5\n",
    "    gs = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=10, scoring='%s_weighted' % score)\n",
    "    gs.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(gs.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in gs.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, gs.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best params are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we repeat kfold analysis with this parameter to check if we get more accuracy than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a composite estimator made by a pipeline of preprocessing and the KNN model\n",
    "model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ds', DecisionTreeClassifier(max_leaf_nodes=None, criterion='gini', \n",
    "                                      splitter='best', class_weight='balanced', max_depth=10,random_state=33))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train) \n",
    "\n",
    "# create a k-fold cross validation iterator of k=10 folds\n",
    "cv = KFold(10, shuffle=True, random_state=33)\n",
    "\n",
    "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "scores = cross_val_score(model, x_digits, y_digits, cv=cv)\n",
    "def mean_score(scores):\n",
    "    return (\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores), sem(scores))\n",
    "print(mean_score(scores))\n",
    "accuracy_tree2 = mean_score(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, with the optimal parameters, we obtain a better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done both algorithms, we see that we can improve a model using the optimal parameters. \n",
    "\n",
    "\n",
    "In knn algorithm we have calculated the accuracy and done the k-fold analysis. We realized that the best neighbour parameter was 1 instead of 15 and changing it we got better accuracy results so the model improves. With kfold the accuracy is more or less the same than with 15 neighbours.\n",
    "\n",
    "\n",
    "In Decision tree learning algorithm we got awful results firstly . With kfold we obtained better results and we calculated some optimal parameters of the model doing an optimization problem (Grid Search) and we have recalculated the accuracy in the k-fold problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
